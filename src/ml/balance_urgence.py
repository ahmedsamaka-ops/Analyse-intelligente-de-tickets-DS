# =============================================================================
# Script de RÃ©Ã©quilibrage du Dataset - Colonne "urgence"
# =============================================================================
# 
# PROBLÃˆME :
# La colonne "urgence" est trÃ¨s dÃ©sÃ©quilibrÃ©e :
#   - Basse     â‰ˆ 94.78% (726 tickets)
#   - Moyenne   â‰ˆ  4.44% (34 tickets)
#   - TrÃ¨s haute â‰ˆ 0.78% (6 tickets)
#
# NORMALISATION :
# La colonne "urgence" doit contenir EXACTEMENT 3 classes :
#   - "Basse", "Moyenne", "Haute"
# Toute occurrence de "TrÃ¨s haute" sera remplacÃ©e par "Haute"
#
# POURQUOI LE RÃ‰Ã‰QUILIBRAGE EST NÃ‰CESSAIRE :
# Un modÃ¨le ML entraÃ®nÃ© sur des donnÃ©es dÃ©sÃ©quilibrÃ©es apprend Ã  prÃ©dire
# majoritairement la classe dominante ("Basse"), ignorant les classes rares.
# RÃ©sultat : le modÃ¨le prÃ©dit toujours "Basse" et rate les urgences rÃ©elles.
#
# POURQUOI ON NE SUPPRIME PAS LA CLASSE MAJORITAIRE :
# - On perdrait ~690 exemples prÃ©cieux d'apprentissage
# - Le modÃ¨le aurait moins de donnÃ©es pour apprendre les patterns "Basse"
# - L'oversampling (sur-Ã©chantillonnage) est prÃ©fÃ©rable : on AUGMENTE les
#   classes minoritaires sans perdre d'information.
#
# MÃ‰THODE : RandomOverSampler (imbalanced-learn)
# - Duplique alÃ©atoirement des exemples de classes minoritaires
# - Plus simple que SMOTE pour les donnÃ©es textuelles
# - PrÃ©serve les vraies donnÃ©es (pas de synthÃ¨se artificielle)
#
# CONTRAINTES :
# - Ne PAS utiliser "categorie", "urgence", "type_ticket", "temps_resolution"
#   comme features d'entrÃ©e pour le modÃ¨le
# - Ne PAS utiliser de deep learning
# - Utiliser uniquement pandas, scikit-learn, imbalanced-learn
#
# =============================================================================

import pandas as pd
import numpy as np
from imblearn.over_sampling import RandomOverSampler
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURATION
# =============================================================================
INPUT_FILE = "data/tickets_cleaned.csv"
OUTPUT_FILE = "data/tickets_balanced.csv"
RANDOM_STATE = 42

# Objectifs de distribution (chaque classe minoritaire â‰¥ 25-30%)
TARGET_MOYENNE_RATIO = 0.28  # ~28% pour "Moyenne"
TARGET_HAUTE_RATIO = 0.22    # ~22% pour "Haute" (moins car moins de donnÃ©es originales)

np.random.seed(RANDOM_STATE)

# =============================================================================
# Ã‰TAPE 1 : CHARGEMENT ET VALIDATION DES COLONNES
# =============================================================================
print("=" * 70)
print("Ã‰TAPE 1 : CHARGEMENT DES DONNÃ‰ES")
print("=" * 70)

df = pd.read_csv(INPUT_FILE)

# Colonnes attendues (ordre exact)
expected_columns = ['ID', 'texte', 'titre', 'categorie', 'urgence', 
                    'temps_resolution', 'type_ticket', 'nb_mots']

print(f"âœ… Fichier chargÃ© : {INPUT_FILE}")
print(f"âœ… Nombre de lignes : {len(df)}")
print(f"âœ… Colonnes trouvÃ©es : {list(df.columns)}")

# Validation de l'ordre des colonnes
if list(df.columns) != expected_columns:
    print(f"âš ï¸  Ordre des colonnes diffÃ©rent de l'attendu")
    print(f"   Attendu : {expected_columns}")
    print(f"   TrouvÃ©  : {list(df.columns)}")
    
# VÃ©rifier que toutes les colonnes sont prÃ©sentes
missing_cols = set(expected_columns) - set(df.columns)
if missing_cols:
    raise ValueError(f"âŒ Colonnes manquantes : {missing_cols}")
print(f"âœ… Toutes les colonnes attendues sont prÃ©sentes")

# =============================================================================
# Ã‰TAPE 2 : NETTOYAGE BASIQUE (texte et titre)
# =============================================================================
print("\n" + "=" * 70)
print("Ã‰TAPE 2 : NETTOYAGE DES DONNÃ‰ES")
print("=" * 70)

# Assurer que texte et titre sont des strings, remplir NaN avec ''
df['texte'] = df['texte'].fillna('').astype(str)
df['titre'] = df['titre'].fillna('').astype(str)

print(f"âœ… Colonnes 'texte' et 'titre' converties en strings")
print(f"âœ… Valeurs NaN remplacÃ©es par des chaÃ®nes vides")

# =============================================================================
# Ã‰TAPE 3 : CRÃ‰ATION DE LA COLONNE text_full
# =============================================================================
print("\n" + "=" * 70)
print("Ã‰TAPE 3 : CRÃ‰ATION DE 'text_full'")
print("=" * 70)

# CrÃ©er la colonne "text_full" = titre + " " + texte
df['text_full'] = df['titre'] + " " + df['texte']
df['text_full'] = df['text_full'].str.strip()

print(f"âœ… Colonne 'text_full' crÃ©Ã©e (titre + ' ' + texte)")
print(f"   Exemple : '{df['text_full'].iloc[0][:60]}...'")

# =============================================================================
# Ã‰TAPE 4 : DISTRIBUTION AVANT NORMALISATION ET Ã‰QUILIBRAGE
# =============================================================================
print("\n" + "=" * 70)
print("Ã‰TAPE 4 : DISTRIBUTION DE 'urgence' AVANT TRAITEMENT")
print("=" * 70)

distribution_avant = df['urgence'].value_counts()
distribution_avant_pct = df['urgence'].value_counts(normalize=True) * 100

print("\nğŸ“Š Distribution ORIGINALE :")
print("-" * 40)
for urgence in distribution_avant.index:
    count = distribution_avant[urgence]
    pct = distribution_avant_pct[urgence]
    bar = "â–ˆ" * int(pct / 2)
    print(f"   {urgence:12} : {count:4} ({pct:5.2f}%) {bar}")

total_avant = len(df)
print(f"\n   TOTAL       : {total_avant}")

# =============================================================================
# Ã‰TAPE 5 : NORMALISATION - "TrÃ¨s haute" â†’ "Haute"
# =============================================================================
print("\n" + "=" * 70)
print("Ã‰TAPE 5 : NORMALISATION DES CLASSES D'URGENCE")
print("=" * 70)

# RÃ¨gle obligatoire : "TrÃ¨s haute" â†’ "Haute"
if 'TrÃ¨s haute' in df['urgence'].values:
    count_tres_haute = (df['urgence'] == 'TrÃ¨s haute').sum()
    print(f"âš ï¸  'TrÃ¨s haute' dÃ©tectÃ©e : {count_tres_haute} occurrences")
    print(f"   â†’ Remplacement par 'Haute' (rÃ¨gle de normalisation)")
    
    df['urgence'] = df['urgence'].replace('TrÃ¨s haute', 'Haute')
    
    print(f"âœ… 'TrÃ¨s haute' remplacÃ©e par 'Haute'")
else:
    print("â„¹ï¸  Pas de 'TrÃ¨s haute' dans les donnÃ©es")

# VÃ©rifier qu'on a maintenant exactement 3 classes
classes_finales = df['urgence'].unique()
print(f"\nâœ… Classes aprÃ¨s normalisation : {sorted(classes_finales)}")

# Afficher distribution aprÃ¨s normalisation
print("\nğŸ“Š Distribution APRÃˆS normalisation :")
print("-" * 40)
distribution_norm = df['urgence'].value_counts()
distribution_norm_pct = df['urgence'].value_counts(normalize=True) * 100

for urgence in ['Basse', 'Moyenne', 'Haute']:
    if urgence in distribution_norm.index:
        count = distribution_norm[urgence]
        pct = distribution_norm_pct[urgence]
        bar = "â–ˆ" * int(pct / 2)
        print(f"   {urgence:12} : {count:4} ({pct:5.2f}%) {bar}")

# =============================================================================
# Ã‰TAPE 6 : OVERSAMPLING AVEC RandomOverSampler
# =============================================================================
print("\n" + "=" * 70)
print("Ã‰TAPE 6 : RÃ‰Ã‰QUILIBRAGE PAR OVERSAMPLING")
print("=" * 70)

# Compter les classes actuelles
count_basse = (df['urgence'] == 'Basse').sum()
count_moyenne = (df['urgence'] == 'Moyenne').sum()
count_haute = (df['urgence'] == 'Haute').sum()

print(f"\nğŸ“ˆ Ã‰tat actuel :")
print(f"   - Basse   : {count_basse}")
print(f"   - Moyenne : {count_moyenne}")
print(f"   - Haute   : {count_haute}")

# Calculer les cibles pour atteindre ~28% Moyenne et ~22% Haute
# Total final = Basse + Moyenne_target + Haute_target
# On rÃ©sout : Moyenne_target / Total = 0.28 et Haute_target / Total = 0.22
# Donc Basse / Total = 0.50, soit Total = Basse / 0.50

# Pour avoir Basse = 50%, Moyenne = 28%, Haute = 22%
total_target = int(count_basse / 0.50)
target_moyenne = int(total_target * TARGET_MOYENNE_RATIO)
target_haute = int(total_target * TARGET_HAUTE_RATIO)

# S'assurer que les targets sont au moins Ã©gaux aux counts actuels
target_moyenne = max(target_moyenne, count_moyenne)
target_haute = max(target_haute, count_haute)

print(f"\nğŸ“ˆ StratÃ©gie d'oversampling :")
print(f"   - Garder TOUS les {count_basse} exemples 'Basse' (aucune suppression)")
print(f"   - Augmenter 'Moyenne' : {count_moyenne} â†’ {target_moyenne} exemples")
print(f"   - Augmenter 'Haute'   : {count_haute} â†’ {target_haute} exemples")

# DÃ©finir la stratÃ©gie de sampling
sampling_strategy = {
    'Basse': count_basse,       # Garder tous (pas de suppression)
    'Moyenne': target_moyenne,   # Augmenter
    'Haute': target_haute        # Augmenter
}

# PrÃ©parer les donnÃ©es pour RandomOverSampler
# On utilise l'index comme X (on veut juste dupliquer des lignes entiÃ¨res)
X = df.index.values.reshape(-1, 1)
y = df['urgence'].values

# Appliquer RandomOverSampler
print("\nğŸ”„ Application de RandomOverSampler...")
ros = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=RANDOM_STATE)
X_resampled, y_resampled = ros.fit_resample(X, y)

print(f"âœ… Oversampling effectuÃ©")
print(f"   - Avant : {len(X)} lignes")
print(f"   - AprÃ¨s : {len(X_resampled)} lignes")

# =============================================================================
# Ã‰TAPE 7 : RECONSTRUCTION DU DATAFRAME AVEC IDs UNIQUES
# =============================================================================
print("\n" + "=" * 70)
print("Ã‰TAPE 7 : RECONSTRUCTION DU DATAFRAME")
print("=" * 70)

# RÃ©cupÃ©rer les indices originaux
original_indices = X_resampled.flatten()

# Reconstruire le DataFrame avec toutes les colonnes
df_balanced = df.iloc[original_indices].copy()

# GÃ©nÃ©rer des IDs uniques pour les lignes dupliquÃ©es
print("ğŸ”¢ GÃ©nÃ©ration d'IDs uniques pour les lignes dupliquÃ©es...")

new_ids = []
id_counter = {}

for i, idx in enumerate(original_indices):
    original_id = df.iloc[idx]['ID']
    
    if original_id not in id_counter:
        id_counter[original_id] = 0
        new_ids.append(original_id)  # PremiÃ¨re occurrence : garder l'ID original
    else:
        id_counter[original_id] += 1
        # Pour les duplications : crÃ©er un nouvel ID unique avec suffixe
        new_id = f"{original_id}_dup_{id_counter[original_id]}"
        new_ids.append(new_id)

df_balanced['ID'] = new_ids

# RÃ©initialiser l'index
df_balanced = df_balanced.reset_index(drop=True)

# RÃ©ordonner les colonnes (colonnes originales + text_full)
final_columns = ['ID', 'texte', 'titre', 'categorie', 'urgence', 
                 'temps_resolution', 'type_ticket', 'nb_mots', 'text_full']
df_balanced = df_balanced[final_columns]

# VÃ©rifier l'unicitÃ© des IDs
n_unique_ids = df_balanced['ID'].nunique()
n_total_rows = len(df_balanced)

print(f"âœ… DataFrame reconstruit avec {n_total_rows} lignes")
print(f"âœ… IDs uniques : {n_unique_ids} / {n_total_rows} (100% unique: {n_unique_ids == n_total_rows})")
print(f"âœ… Colonnes finales : {list(df_balanced.columns)}")

# =============================================================================
# Ã‰TAPE 8 : DISTRIBUTION APRÃˆS Ã‰QUILIBRAGE
# =============================================================================
print("\n" + "=" * 70)
print("Ã‰TAPE 8 : DISTRIBUTION DE 'urgence' APRÃˆS Ã‰QUILIBRAGE")
print("=" * 70)

distribution_apres = df_balanced['urgence'].value_counts()
distribution_apres_pct = df_balanced['urgence'].value_counts(normalize=True) * 100

print("\nğŸ“Š Distribution FINALE :")
print("-" * 40)
for urgence in ['Basse', 'Moyenne', 'Haute']:
    if urgence in distribution_apres.index:
        count = distribution_apres[urgence]
        pct = distribution_apres_pct[urgence]
        bar = "â–ˆ" * int(pct / 2)
        print(f"   {urgence:12} : {count:4} ({pct:5.2f}%) {bar}")

total_apres = len(df_balanced)
print(f"\n   TOTAL       : {total_apres}")

# =============================================================================
# RÃ‰SUMÃ‰ COMPARATIF
# =============================================================================
print("\n" + "=" * 70)
print("RÃ‰SUMÃ‰ : COMPARAISON AVANT / APRÃˆS")
print("=" * 70)

print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AVANT Ã‰QUILIBRAGE                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Total      : {total_avant:4} tickets                                       â”‚
â”‚  â€¢ Basse      : {distribution_norm.get('Basse', 0):4} ({distribution_norm_pct.get('Basse', 0):5.2f}%)                                 â”‚
â”‚  â€¢ Moyenne    : {distribution_norm.get('Moyenne', 0):4} ({distribution_norm_pct.get('Moyenne', 0):5.2f}%)                                  â”‚
â”‚  â€¢ Haute      : {distribution_norm.get('Haute', 0):4} ({distribution_norm_pct.get('Haute', 0):5.2f}%)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  APRÃˆS Ã‰QUILIBRAGE (RandomOverSampler)                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Total      : {total_apres:4} tickets                                      â”‚
â”‚  â€¢ Basse      : {distribution_apres.get('Basse', 0):4} ({distribution_apres_pct.get('Basse', 0):5.2f}%)                                 â”‚
â”‚  â€¢ Moyenne    : {distribution_apres.get('Moyenne', 0):4} ({distribution_apres_pct.get('Moyenne', 0):5.2f}%)                                 â”‚
â”‚  â€¢ Haute      : {distribution_apres.get('Haute', 0):4} ({distribution_apres_pct.get('Haute', 0):5.2f}%)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# =============================================================================
# Ã‰TAPE 9 : SAUVEGARDE DU FICHIER Ã‰QUILIBRÃ‰
# =============================================================================
print("=" * 70)
print("Ã‰TAPE 9 : SAUVEGARDE")
print("=" * 70)

df_balanced.to_csv(OUTPUT_FILE, index=False)

print(f"âœ… Dataset Ã©quilibrÃ© sauvegardÃ© : {OUTPUT_FILE}")
print(f"âœ… Nombre de lignes : {len(df_balanced)}")
print(f"âœ… Colonnes : {list(df_balanced.columns)}")

# Rappel des contraintes
print("\n" + "-" * 70)
print("ğŸ“Œ RAPPEL : Pour l'entraÃ®nement du modÃ¨le, utiliser UNIQUEMENT :")
print("   - INPUT  : 'text_full' (ou 'texte' + 'titre')")
print("   - OUTPUT : 'urgence' (Basse, Moyenne, Haute)")
print("   - NE PAS utiliser : categorie, type_ticket, temps_resolution")
print("-" * 70)

print("\n" + "=" * 70)
print("âœ… RÃ‰Ã‰QUILIBRAGE TERMINÃ‰ AVEC SUCCÃˆS !")
print("=" * 70)
