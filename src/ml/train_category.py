# =============================================================================
# Entra√Ænement du Mod√®le de Cat√©gorie (Classification multi-classes)
# =============================================================================
"""
MOD√àLE 2 : Pr√©diction de la cat√©gorie des tickets
- Classes : Multiples cat√©gories (variable selon le dataset)
- Features : TF-IDF(text_full) + nb_mots + urgence_pred (encod√© OneHot)
- Algorithme : LogisticRegression ou LinearSVC

ANTI-FUITE : utilise urgence_pred OOF (pas les vraies valeurs d'urgence)
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import OneHotEncoder
from sklearn.base import clone
from scipy.sparse import hstack, csr_matrix
import warnings
warnings.filterwarnings('ignore')

from ml_utils import (
    load_data, ensure_models_dir, save_model, save_metadata, load_model,
    evaluate_classification, generate_oof_predictions_with_categorical,
    TFIDF_PARAMS, RANDOM_STATE, N_FOLDS, MODELS_DIR
)

# =============================================================================
# CONFIGURATION
# =============================================================================
MODEL_NAME = "category_model"
PIPELINE_FILE = "category_pipeline.pkl"
TEXT_COLUMN = "text_full"
NUMERIC_COLUMNS = ["nb_mots"]
CATEGORICAL_PRED_COLUMNS = ["urgence_pred"]  # Pr√©diction upstream (pas le vrai label!)
TARGET_COLUMN = "categorie"

# =============================================================================
# FONCTION PRINCIPALE D'ENTRA√éNEMENT
# =============================================================================
def train_category_model(df_train: pd.DataFrame = None, 
                        df_val: pd.DataFrame = None, 
                        df_test: pd.DataFrame = None):
    """
    Entra√Æne le mod√®le de pr√©diction de cat√©gorie.
    
    IMPORTANT : N√©cessite que urgence_pred soit d√©j√† pr√©sent dans les DataFrames.
    Si non fourni, charge les fichiers avec pr√©dictions d'urgence.
    
    Args:
        df_train, df_val, df_test: DataFrames avec urgence_pred (optionnel)
        
    Returns:
        Tuple: (pipeline_dict, df_train avec oof_pred, df_val avec pred, df_test avec pred)
    """
    print("=" * 70)
    print("ENTRA√éNEMENT DU MOD√àLE DE CAT√âGORIE")
    print("=" * 70)
    print(f"Target : {TARGET_COLUMN}")
    print(f"Features : TF-IDF({TEXT_COLUMN}) + {NUMERIC_COLUMNS} + {CATEGORICAL_PRED_COLUMNS}")
    print(f"Algorithme : LogisticRegression (multi-class)")
    print()
    
    # -------------------------------------------------------------------------
    # √âTAPE 1 : Chargement des donn√©es avec pr√©dictions d'urgence
    # -------------------------------------------------------------------------
    print("\n" + "-" * 70)
    print("√âTAPE 1 : Chargement des donn√©es")
    print("-" * 70)
    
    if df_train is None or df_val is None or df_test is None:
        # Charger les fichiers avec pr√©dictions d'urgence
        try:
            df_train = pd.read_csv("data/train_with_urgence_pred.csv")
            df_val = pd.read_csv("data/val_with_urgence_pred.csv")
            df_test = pd.read_csv("data/test_with_urgence_pred.csv")
            print("‚úÖ Charg√© depuis les fichiers *_with_urgence_pred.csv")
        except FileNotFoundError:
            print("‚ùå Fichiers avec pr√©dictions d'urgence non trouv√©s.")
            print("   Veuillez d'abord ex√©cuter train_urgency.py")
            return None
    
    # V√©rifier que urgence_pred existe
    if 'urgence_pred' not in df_train.columns:
        print("‚ùå Colonne 'urgence_pred' manquante dans le train set.")
        print("   Veuillez d'abord ex√©cuter train_urgency.py")
        return None
    
    print(f"   Train      : {len(df_train)} lignes")
    print(f"   Validation : {len(df_val)} lignes")
    print(f"   Test       : {len(df_test)} lignes")
    
    # Identifier les classes de cat√©gorie
    category_labels = sorted(df_train[TARGET_COLUMN].unique())
    n_classes = len(category_labels)
    print(f"\nüìä Nombre de cat√©gories : {n_classes}")
    print(f"   Classes : {category_labels[:5]}..." if n_classes > 5 else f"   Classes : {category_labels}")
    
    # Distribution
    print(f"\nüìä Distribution des cat√©gories (top 5):")
    dist = df_train[TARGET_COLUMN].value_counts()
    for label in dist.index[:5]:
        pct = dist[label] / len(df_train) * 100
        print(f"   {label}: {dist[label]} ({pct:.2f}%)")
    
    # -------------------------------------------------------------------------
    # √âTAPE 2 : G√©n√©ration des pr√©dictions OOF sur le train set
    # -------------------------------------------------------------------------
    print("\n" + "-" * 70)
    print("√âTAPE 2 : G√©n√©ration des pr√©dictions Out-Of-Fold (OOF)")
    print("-" * 70)
    print("""
    ANTI-FUITE : On utilise urgence_pred (pas urgence r√©elle) comme feature.
    Ces pr√©dictions ont √©t√© g√©n√©r√©es en OOF donc pas de fuite.
    
    Maintenant on g√©n√®re les pr√©dictions OOF de CAT√âGORIE pour les utiliser
    dans les mod√®les downstream (type_ticket, temps_resolution).
    """)
    
    # D√©finir le mod√®le de base
    base_model = LogisticRegression(
        max_iter=2000,
        random_state=RANDOM_STATE,
        solver='lbfgs',
        n_jobs=-1
    )
    
    # G√©n√©rer les pr√©dictions OOF
    oof_predictions = generate_oof_predictions_with_categorical(
        model=base_model,
        X=df_train,
        y=df_train[TARGET_COLUMN],
        text_column=TEXT_COLUMN,
        numeric_columns=NUMERIC_COLUMNS,
        categorical_pred_columns=CATEGORICAL_PRED_COLUMNS,
        n_folds=N_FOLDS,
        random_state=RANDOM_STATE
    )
    
    # Ajouter les pr√©dictions OOF au DataFrame train
    df_train['categorie_pred'] = oof_predictions
    
    # √âvaluation OOF
    print("\nüìä Performance OOF sur le Train Set:")
    oof_metrics = evaluate_classification(
        df_train[TARGET_COLUMN], 
        oof_predictions, 
        "Train (OOF)",
        labels=category_labels
    )
    
    # -------------------------------------------------------------------------
    # √âTAPE 3 : Entra√Ænement du mod√®le final sur tout le train set
    # -------------------------------------------------------------------------
    print("\n" + "-" * 70)
    print("√âTAPE 3 : Entra√Ænement du mod√®le FINAL sur tout le train set")
    print("-" * 70)
    
    # TF-IDF
    tfidf_final = TfidfVectorizer(**TFIDF_PARAMS)
    X_text_train = tfidf_final.fit_transform(df_train[TEXT_COLUMN].fillna(''))
    
    # Features num√©riques
    X_num_train = df_train[NUMERIC_COLUMNS].values
    
    # Encoder les pr√©dictions cat√©gorielles (urgence_pred)
    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)
    X_cat_train = encoder.fit_transform(df_train[CATEGORICAL_PRED_COLUMNS])
    
    # Combiner toutes les features
    X_train_combined = hstack([X_text_train, csr_matrix(X_num_train), X_cat_train])
    
    print(f"   Shape features combin√©es : {X_train_combined.shape}")
    print(f"   - TF-IDF features : {X_text_train.shape[1]}")
    print(f"   - Numeric features : {len(NUMERIC_COLUMNS)}")
    print(f"   - Categorical features (urgence_pred encoded) : {X_cat_train.shape[1]}")
    
    # Entra√Æner le mod√®le final
    final_model = LogisticRegression(
        max_iter=2000,
        random_state=RANDOM_STATE,
        solver='lbfgs',
        n_jobs=-1
    )
    final_model.fit(X_train_combined, df_train[TARGET_COLUMN])
    print("   ‚úÖ Mod√®le final entra√Æn√©")
    
    # -------------------------------------------------------------------------
    # √âTAPE 4 : Pr√©dictions et √©valuation sur Validation et Test
    # -------------------------------------------------------------------------
    print("\n" + "-" * 70)
    print("√âTAPE 4 : √âvaluation sur Validation et Test")
    print("-" * 70)
    
    # Pr√©dictions sur validation
    X_text_val = tfidf_final.transform(df_val[TEXT_COLUMN].fillna(''))
    X_num_val = df_val[NUMERIC_COLUMNS].values
    X_cat_val = encoder.transform(df_val[CATEGORICAL_PRED_COLUMNS])
    X_val_combined = hstack([X_text_val, csr_matrix(X_num_val), X_cat_val])
    
    val_predictions = final_model.predict(X_val_combined)
    df_val['categorie_pred'] = val_predictions
    
    val_metrics = evaluate_classification(
        df_val[TARGET_COLUMN],
        val_predictions,
        "VALIDATION",
        labels=category_labels
    )
    
    # Pr√©dictions sur test
    X_text_test = tfidf_final.transform(df_test[TEXT_COLUMN].fillna(''))
    X_num_test = df_test[NUMERIC_COLUMNS].values
    X_cat_test = encoder.transform(df_test[CATEGORICAL_PRED_COLUMNS])
    X_test_combined = hstack([X_text_test, csr_matrix(X_num_test), X_cat_test])
    
    test_predictions = final_model.predict(X_test_combined)
    df_test['categorie_pred'] = test_predictions
    
    test_metrics = evaluate_classification(
        df_test[TARGET_COLUMN],
        test_predictions,
        "TEST",
        labels=category_labels
    )
    
    # -------------------------------------------------------------------------
    # √âTAPE 5 : Sauvegarde du pipeline et des m√©tadonn√©es
    # -------------------------------------------------------------------------
    print("\n" + "-" * 70)
    print("√âTAPE 5 : Sauvegarde du mod√®le")
    print("-" * 70)
    
    ensure_models_dir()
    
    # Cr√©er le dictionnaire pipeline
    pipeline_dict = {
        'model': final_model,
        'tfidf': tfidf_final,
        'encoder': encoder,
        'text_column': TEXT_COLUMN,
        'numeric_columns': NUMERIC_COLUMNS,
        'categorical_pred_columns': CATEGORICAL_PRED_COLUMNS,
        'target_column': TARGET_COLUMN,
        'labels': category_labels
    }
    
    save_model(pipeline_dict, PIPELINE_FILE, "Pipeline Cat√©gorie")
    
    # Sauvegarder les m√©tadonn√©es
    metadata = {
        'category_model': {
            'training_date': datetime.now().isoformat(),
            'algorithm': 'LogisticRegression (multinomial)',
            'features': {
                'text': TEXT_COLUMN,
                'numeric': NUMERIC_COLUMNS,
                'categorical_pred': CATEGORICAL_PRED_COLUMNS,
                'tfidf_params': TFIDF_PARAMS
            },
            'n_classes': n_classes,
            'classes': category_labels,
            'metrics': {
                'oof_train': oof_metrics,
                'validation': val_metrics,
                'test': test_metrics
            },
            'n_train_samples': len(df_train),
            'n_features': X_train_combined.shape[1]
        }
    }
    save_metadata(metadata)
    
    # -------------------------------------------------------------------------
    # R√âSUM√â FINAL
    # -------------------------------------------------------------------------
    print("\n" + "=" * 70)
    print("R√âSUM√â - MOD√àLE DE CAT√âGORIE")
    print("=" * 70)
    print(f"""
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  MOD√àLE DE CAT√âGORIE (Classification {n_classes} classes)               ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  Features : TF-IDF + nb_mots + urgence_pred (OneHot)                ‚îÇ
    ‚îÇ  Algorithme : LogisticRegression (multinomial)                      ‚îÇ
    ‚îÇ                                                                     ‚îÇ
    ‚îÇ  üìä PERFORMANCES :                                                  ‚îÇ
    ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
    ‚îÇ  Train (OOF)  : Accuracy={oof_metrics['accuracy']:.4f}  F1-Macro={oof_metrics['f1_macro']:.4f}  ‚îÇ
    ‚îÇ  Validation   : Accuracy={val_metrics['accuracy']:.4f}  F1-Macro={val_metrics['f1_macro']:.4f}  ‚îÇ
    ‚îÇ  Test         : Accuracy={test_metrics['accuracy']:.4f}  F1-Macro={test_metrics['f1_macro']:.4f}  ‚îÇ
    ‚îÇ                                                                     ‚îÇ
    ‚îÇ  ‚úÖ Pipeline sauvegard√© : models/{PIPELINE_FILE}            ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    """)
    
    return pipeline_dict, df_train, df_val, df_test


# =============================================================================
# FONCTION DE PR√âDICTION POUR UTILISATION EXTERNE
# =============================================================================
def predict_category(pipeline_dict: dict, X: pd.DataFrame) -> np.ndarray:
    """
    Fait des pr√©dictions de cat√©gorie sur de nouvelles donn√©es.
    
    Args:
        pipeline_dict: Dictionnaire contenant le mod√®le et les transformers
        X: DataFrame avec text_full, nb_mots, et urgence_pred
        
    Returns:
        Array de pr√©dictions
    """
    tfidf = pipeline_dict['tfidf']
    model = pipeline_dict['model']
    encoder = pipeline_dict['encoder']
    text_col = pipeline_dict['text_column']
    num_cols = pipeline_dict['numeric_columns']
    cat_cols = pipeline_dict['categorical_pred_columns']
    
    X_text = tfidf.transform(X[text_col].fillna(''))
    X_num = X[num_cols].values
    X_cat = encoder.transform(X[cat_cols])
    X_combined = hstack([X_text, csr_matrix(X_num), X_cat])
    
    return model.predict(X_combined)


# =============================================================================
# POINT D'ENTR√âE
# =============================================================================
if __name__ == "__main__":
    result = train_category_model()
    
    if result is not None:
        pipeline, df_train, df_val, df_test = result
        
        # Sauvegarder les DataFrames avec les pr√©dictions pour les mod√®les suivants
        df_train.to_csv("data/train_with_categorie_pred.csv", index=False)
        df_val.to_csv("data/val_with_categorie_pred.csv", index=False)
        df_test.to_csv("data/test_with_categorie_pred.csv", index=False)
        
        print("\n‚úÖ DataFrames avec pr√©dictions de cat√©gorie sauvegard√©s pour les mod√®les downstream")
    
    print("=" * 70)
