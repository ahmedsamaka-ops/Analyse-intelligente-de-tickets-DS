# =============================================================================
# Script de Split Stratifi√© du Dataset √âquilibr√©
# =============================================================================
#
# OBJECTIF :
# Diviser "tickets_balanced.csv" en 3 ensembles :
#   - train.csv      = 70% (entra√Ænement)
#   - validation.csv = 15% (validation/tuning)
#   - test.csv       = 15% (√©valuation finale)
#
# POURQUOI UN SPLIT STRATIFI√â ?
# -----------------------------
# Un split stratifi√© garantit que la distribution des classes (urgence) est
# IDENTIQUE dans chaque ensemble (train, validation, test).
# 
# Sans stratification, on risque d'avoir par exemple :
#   - Train avec 60% Basse, 30% Moyenne, 10% Haute
#   - Test avec 40% Basse, 20% Moyenne, 40% Haute
# 
# Cela biaiserait l'√©valuation : le mod√®le serait entra√Æn√© sur une distribution
# diff√©rente de celle sur laquelle il est test√©.
#
# Avec stratification (notre cas) :
#   - Train : 50% Basse, 28% Moyenne, 22% Haute
#   - Val   : 50% Basse, 28% Moyenne, 22% Haute
#   - Test  : 50% Basse, 28% Moyenne, 22% Haute
#
# POURQUOI random_state=42 ?
# --------------------------
# Fixer le random_state garantit la REPRODUCTIBILIT√â :
#   - Chaque ex√©cution du script produit exactement le m√™me split
#   - Permet de comparer des exp√©riences sur les m√™mes donn√©es
#   - Facilite le debugging et la collaboration en √©quipe
#   - 42 est une convention (r√©f√©rence au "Guide du voyageur galactique")
#
# =============================================================================

import pandas as pd
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURATION
# =============================================================================
INPUT_FILE = "data/tickets_balanced.csv"
OUTPUT_DIR = "data"
TRAIN_FILE = f"{OUTPUT_DIR}/train.csv"
VAL_FILE = f"{OUTPUT_DIR}/validation.csv"
TEST_FILE = f"{OUTPUT_DIR}/test.csv"

# Proportions du split
TRAIN_RATIO = 0.70  # 70% pour l'entra√Ænement
VAL_RATIO = 0.15    # 15% pour la validation
TEST_RATIO = 0.15   # 15% pour le test

# Seed pour la reproductibilit√©
RANDOM_STATE = 42

# Colonnes attendues (ordre exact)
EXPECTED_COLUMNS = ['ID', 'texte', 'titre', 'categorie', 'urgence', 
                    'temps_resolution', 'type_ticket', 'nb_mots', 'text_full']

# Valeurs valides pour urgence
VALID_URGENCE = {'Basse', 'Moyenne', 'Haute'}

# =============================================================================
# √âTAPE 1 : CHARGEMENT DES DONN√âES
# =============================================================================
print("=" * 70)
print("√âTAPE 1 : CHARGEMENT DES DONN√âES")
print("=" * 70)

df = pd.read_csv(INPUT_FILE)

print(f"‚úÖ Fichier charg√© : {INPUT_FILE}")
print(f"‚úÖ Nombre de lignes : {len(df)}")
print(f"‚úÖ Colonnes trouv√©es : {list(df.columns)}")

# =============================================================================
# √âTAPE 2 : VALIDATION DES COLONNES
# =============================================================================
print("\n" + "=" * 70)
print("√âTAPE 2 : VALIDATION DES COLONNES")
print("=" * 70)

# V√©rifier que toutes les colonnes attendues sont pr√©sentes
missing_cols = set(EXPECTED_COLUMNS) - set(df.columns)
extra_cols = set(df.columns) - set(EXPECTED_COLUMNS)

if missing_cols:
    raise ValueError(f"‚ùå Colonnes manquantes : {missing_cols}")
if extra_cols:
    print(f"‚ö†Ô∏è  Colonnes suppl√©mentaires ignor√©es : {extra_cols}")

print(f"‚úÖ Toutes les colonnes attendues sont pr√©sentes")

# R√©ordonner les colonnes selon l'ordre attendu
df = df[EXPECTED_COLUMNS]
print(f"‚úÖ Colonnes r√©ordonn√©es : {list(df.columns)}")

# =============================================================================
# √âTAPE 3 : VALIDATION DES DONN√âES
# =============================================================================
print("\n" + "=" * 70)
print("√âTAPE 3 : VALIDATION DES DONN√âES")
print("=" * 70)

# 3.1 V√©rifier l'unicit√© des IDs
n_unique_ids = df['ID'].nunique()
n_total_rows = len(df)

if n_unique_ids != n_total_rows:
    duplicates = df[df['ID'].duplicated(keep=False)]['ID'].unique()
    raise ValueError(f"‚ùå IDs non uniques d√©tect√©s ! {n_total_rows - n_unique_ids} doublons. "
                     f"Exemples : {list(duplicates[:5])}")
print(f"‚úÖ Tous les IDs sont uniques ({n_unique_ids}/{n_total_rows})")

# 3.2 V√©rifier les valeurs de urgence
urgence_values = set(df['urgence'].unique())
invalid_values = urgence_values - VALID_URGENCE

if invalid_values:
    raise ValueError(f"‚ùå Valeurs d'urgence invalides : {invalid_values}. "
                     f"Attendues : {VALID_URGENCE}")
print(f"‚úÖ Valeurs d'urgence valides : {sorted(urgence_values)}")

# =============================================================================
# √âTAPE 4 : SPLIT STRATIFI√â EN DEUX √âTAPES
# =============================================================================
print("\n" + "=" * 70)
print("√âTAPE 4 : SPLIT STRATIFI√â")
print("=" * 70)

print(f"\nüìä Distribution AVANT split :")
print("-" * 40)
dist_total = df['urgence'].value_counts()
dist_total_pct = df['urgence'].value_counts(normalize=True) * 100
for urgence in ['Basse', 'Moyenne', 'Haute']:
    if urgence in dist_total.index:
        print(f"   {urgence:10} : {dist_total[urgence]:4} ({dist_total_pct[urgence]:5.2f}%)")
print(f"   TOTAL     : {len(df)}")

# --- √âTAPE 4a : Premier split - 70% train, 30% temp ---
print(f"\nüîÑ Split 1 : 70% train, 30% temp (stratifi√© sur 'urgence')")

df_train, df_temp = train_test_split(
    df,
    test_size=0.30,           # 30% pour temp (validation + test)
    stratify=df['urgence'],   # Stratification sur la colonne urgence
    random_state=RANDOM_STATE,
    shuffle=True
)

print(f"   ‚Üí Train : {len(df_train)} lignes ({len(df_train)/len(df)*100:.1f}%)")
print(f"   ‚Üí Temp  : {len(df_temp)} lignes ({len(df_temp)/len(df)*100:.1f}%)")

# --- √âTAPE 4b : Second split - 50% validation, 50% test (du temp) ---
print(f"\nüîÑ Split 2 : 50% validation, 50% test du temp (stratifi√© sur 'urgence')")

df_val, df_test = train_test_split(
    df_temp,
    test_size=0.50,              # 50% du temp = 15% du total
    stratify=df_temp['urgence'], # Stratification sur la colonne urgence
    random_state=RANDOM_STATE,
    shuffle=True
)

print(f"   ‚Üí Validation : {len(df_val)} lignes ({len(df_val)/len(df)*100:.1f}%)")
print(f"   ‚Üí Test       : {len(df_test)} lignes ({len(df_test)/len(df)*100:.1f}%)")

# R√©initialiser les index
df_train = df_train.reset_index(drop=True)
df_val = df_val.reset_index(drop=True)
df_test = df_test.reset_index(drop=True)

# =============================================================================
# √âTAPE 5 : AFFICHAGE DES DISTRIBUTIONS PAR ENSEMBLE
# =============================================================================
print("\n" + "=" * 70)
print("√âTAPE 5 : DISTRIBUTION DE 'urgence' PAR ENSEMBLE")
print("=" * 70)

def print_distribution(df_set, set_name):
    """Affiche la distribution d'urgence pour un ensemble."""
    print(f"\nüìä {set_name} ({len(df_set)} lignes) :")
    print("-" * 40)
    dist = df_set['urgence'].value_counts()
    dist_pct = df_set['urgence'].value_counts(normalize=True) * 100
    for urgence in ['Basse', 'Moyenne', 'Haute']:
        if urgence in dist.index:
            bar = "‚ñà" * int(dist_pct[urgence] / 2)
            print(f"   {urgence:10} : {dist[urgence]:4} ({dist_pct[urgence]:5.2f}%) {bar}")

print_distribution(df_train, "TRAIN (70%)")
print_distribution(df_val, "VALIDATION (15%)")
print_distribution(df_test, "TEST (15%)")

# =============================================================================
# √âTAPE 6 : V√âRIFICATION DE LA STRATIFICATION
# =============================================================================
print("\n" + "=" * 70)
print("√âTAPE 6 : V√âRIFICATION DE LA STRATIFICATION")
print("=" * 70)

print("\nüìà Comparaison des proportions (%) :")
print("-" * 60)
print(f"{'Ensemble':<15} {'Basse':>10} {'Moyenne':>10} {'Haute':>10}")
print("-" * 60)

for name, df_set in [('Original', df), ('Train', df_train), ('Validation', df_val), ('Test', df_test)]:
    pct = df_set['urgence'].value_counts(normalize=True) * 100
    print(f"{name:<15} {pct.get('Basse', 0):>10.2f} {pct.get('Moyenne', 0):>10.2f} {pct.get('Haute', 0):>10.2f}")

print("-" * 60)
print("‚úÖ Les proportions sont identiques dans tous les ensembles (stratification r√©ussie)")

# =============================================================================
# √âTAPE 7 : SAUVEGARDE DES FICHIERS CSV
# =============================================================================
print("\n" + "=" * 70)
print("√âTAPE 7 : SAUVEGARDE DES FICHIERS")
print("=" * 70)

# Sauvegarder avec les m√™mes colonnes et ordre que l'input
df_train.to_csv(TRAIN_FILE, index=False)
df_val.to_csv(VAL_FILE, index=False)
df_test.to_csv(TEST_FILE, index=False)

print(f"‚úÖ {TRAIN_FILE:<25} : {len(df_train):5} lignes (70%)")
print(f"‚úÖ {VAL_FILE:<25} : {len(df_val):5} lignes (15%)")
print(f"‚úÖ {TEST_FILE:<25} : {len(df_test):5} lignes (15%)")

# V√©rification finale
total_saved = len(df_train) + len(df_val) + len(df_test)
print(f"\nüìä Total sauvegard√© : {total_saved} lignes")
print(f"üìä Total original   : {len(df)} lignes")
print(f"‚úÖ V√©rification : {total_saved} == {len(df)} : {total_saved == len(df)}")

# =============================================================================
# R√âSUM√â FINAL
# =============================================================================
print("\n" + "=" * 70)
print("R√âSUM√â DU SPLIT STRATIFI√â")
print("=" * 70)

print(f"""
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FICHIER SOURCE : tickets_balanced.csv ({len(df)} lignes)              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  SPLIT STRATIFI√â (random_state=42)                                  ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  üìÅ train.csv      : {len(df_train):5} lignes (70%)                        ‚îÇ
‚îÇ  üìÅ validation.csv : {len(df_val):5} lignes (15%)                         ‚îÇ
‚îÇ  üìÅ test.csv       : {len(df_test):5} lignes (15%)                         ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚úÖ Distribution pr√©serv√©e dans tous les ensembles                  ‚îÇ
‚îÇ  ‚úÖ Reproductible (m√™me r√©sultat √† chaque ex√©cution)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
""")

print("=" * 70)
print("‚úÖ SPLIT STRATIFI√â TERMIN√â AVEC SUCC√àS !")
print("=" * 70)
