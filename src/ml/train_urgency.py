# =============================================================================
# Entra√Ænement du Mod√®le d'Urgence (Classification 3 classes)
# =============================================================================
"""
MOD√àLE 1 : Pr√©diction de l'urgence des tickets
- Classes : Basse, Moyenne, Haute
- Features : TF-IDF(text_full) + nb_mots
- Algorithme : LogisticRegression avec class_weight='balanced'

Ce mod√®le est le PREMIER de la cha√Æne. Ses pr√©dictions OOF seront utilis√©es
comme features pour les mod√®les downstream (category, type, time).
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.base import clone
from scipy.sparse import hstack, csr_matrix
import warnings
warnings.filterwarnings('ignore')

from ml_utils import (
    load_data, ensure_models_dir, save_model, save_metadata,
    evaluate_classification, generate_oof_predictions_classification,
    TFIDF_PARAMS, RANDOM_STATE, N_FOLDS, MODELS_DIR
)

# =============================================================================
# CONFIGURATION
# =============================================================================
MODEL_NAME = "urgency_model"
PIPELINE_FILE = "urgency_pipeline.pkl"
TEXT_COLUMN = "text_full"
NUMERIC_COLUMNS = ["nb_mots"]
TARGET_COLUMN = "urgence"
URGENCY_LABELS = ['Basse', 'Moyenne', 'Haute']

# =============================================================================
# FONCTION PRINCIPALE D'ENTRA√éNEMENT
# =============================================================================
def train_urgency_model():
    """
    Entra√Æne le mod√®le de pr√©diction d'urgence.
    
    Steps:
    1. Charger les donn√©es
    2. G√©n√©rer les pr√©dictions OOF sur le train set
    3. Entra√Æner le mod√®le final sur tout le train set
    4. √âvaluer sur validation et test
    5. Sauvegarder le pipeline et les m√©tadonn√©es
    
    Returns:
        Tuple: (pipeline_dict, df_train avec oof_pred, df_val avec pred, df_test avec pred)
    """
    print("=" * 70)
    print("ENTRA√éNEMENT DU MOD√àLE D'URGENCE")
    print("=" * 70)
    print(f"Target : {TARGET_COLUMN}")
    print(f"Classes : {URGENCY_LABELS}")
    print(f"Features : TF-IDF({TEXT_COLUMN}) + {NUMERIC_COLUMNS}")
    print(f"Algorithme : LogisticRegression (class_weight='balanced')")
    print()
    
    # -------------------------------------------------------------------------
    # √âTAPE 1 : Chargement des donn√©es
    # -------------------------------------------------------------------------
    print("\n" + "-" * 70)
    print("√âTAPE 1 : Chargement des donn√©es")
    print("-" * 70)
    
    df_train, df_val, df_test = load_data()
    
    # V√©rifier les classes
    print(f"\nüìä Distribution d'urgence dans le train set:")
    dist = df_train[TARGET_COLUMN].value_counts()
    for label in URGENCY_LABELS:
        pct = dist[label] / len(df_train) * 100
        print(f"   {label}: {dist[label]} ({pct:.2f}%)")
    
    # -------------------------------------------------------------------------
    # √âTAPE 2 : G√©n√©ration des pr√©dictions OOF sur le train set
    # -------------------------------------------------------------------------
    print("\n" + "-" * 70)
    print("√âTAPE 2 : G√©n√©ration des pr√©dictions Out-Of-Fold (OOF)")
    print("-" * 70)
    print("""
    POURQUOI OOF ?
    Les pr√©dictions d'urgence seront utilis√©es comme features pour les mod√®les
    downstream (category, type, time). Pour √©viter la FUITE DE DONN√âES, on ne
    peut pas utiliser les pr√©dictions du mod√®le entra√Æn√© sur tout le train set.
    
    Solution : K-Fold CV o√π chaque pr√©diction est faite par un mod√®le qui n'a
    JAMAIS vu cette donn√©e.
    """)
    
    # D√©finir le mod√®le de base
    base_model = LogisticRegression(
        max_iter=2000,
        class_weight='balanced',
        random_state=RANDOM_STATE,
        solver='lbfgs',
        n_jobs=-1
    )
    
    # G√©n√©rer les pr√©dictions OOF
    oof_predictions = generate_oof_predictions_classification(
        model=base_model,
        X=df_train,
        y=df_train[TARGET_COLUMN],
        feature_columns=NUMERIC_COLUMNS,
        text_column=TEXT_COLUMN,
        n_folds=N_FOLDS,
        random_state=RANDOM_STATE
    )
    
    # Ajouter les pr√©dictions OOF au DataFrame train
    df_train['urgence_pred'] = oof_predictions
    
    # √âvaluation OOF
    print("\nüìä Performance OOF sur le Train Set:")
    oof_metrics = evaluate_classification(
        df_train[TARGET_COLUMN], 
        oof_predictions, 
        "Train (OOF)",
        labels=URGENCY_LABELS
    )
    
    # -------------------------------------------------------------------------
    # √âTAPE 3 : Entra√Ænement du mod√®le final sur tout le train set
    # -------------------------------------------------------------------------
    print("\n" + "-" * 70)
    print("√âTAPE 3 : Entra√Ænement du mod√®le FINAL sur tout le train set")
    print("-" * 70)
    
    # Cr√©er et fitter le vectorizer TF-IDF final
    tfidf_final = TfidfVectorizer(**TFIDF_PARAMS)
    X_text_train = tfidf_final.fit_transform(df_train[TEXT_COLUMN].fillna(''))
    
    # Ajouter les features num√©riques
    X_num_train = df_train[NUMERIC_COLUMNS].values
    X_train_combined = hstack([X_text_train, csr_matrix(X_num_train)])
    
    print(f"   Shape features combin√©es : {X_train_combined.shape}")
    print(f"   - TF-IDF features : {X_text_train.shape[1]}")
    print(f"   - Numeric features : {len(NUMERIC_COLUMNS)}")
    
    # Entra√Æner le mod√®le final
    final_model = LogisticRegression(
        max_iter=2000,
        class_weight='balanced',
        random_state=RANDOM_STATE,
        solver='lbfgs',
        n_jobs=-1
    )
    final_model.fit(X_train_combined, df_train[TARGET_COLUMN])
    print("   ‚úÖ Mod√®le final entra√Æn√©")
    
    # -------------------------------------------------------------------------
    # √âTAPE 4 : Pr√©dictions et √©valuation sur Validation et Test
    # -------------------------------------------------------------------------
    print("\n" + "-" * 70)
    print("√âTAPE 4 : √âvaluation sur Validation et Test")
    print("-" * 70)
    
    # Pr√©dictions sur validation
    X_text_val = tfidf_final.transform(df_val[TEXT_COLUMN].fillna(''))
    X_num_val = df_val[NUMERIC_COLUMNS].values
    X_val_combined = hstack([X_text_val, csr_matrix(X_num_val)])
    
    val_predictions = final_model.predict(X_val_combined)
    df_val['urgence_pred'] = val_predictions
    
    val_metrics = evaluate_classification(
        df_val[TARGET_COLUMN],
        val_predictions,
        "VALIDATION",
        labels=URGENCY_LABELS
    )
    
    # Pr√©dictions sur test
    X_text_test = tfidf_final.transform(df_test[TEXT_COLUMN].fillna(''))
    X_num_test = df_test[NUMERIC_COLUMNS].values
    X_test_combined = hstack([X_text_test, csr_matrix(X_num_test)])
    
    test_predictions = final_model.predict(X_test_combined)
    df_test['urgence_pred'] = test_predictions
    
    test_metrics = evaluate_classification(
        df_test[TARGET_COLUMN],
        test_predictions,
        "TEST",
        labels=URGENCY_LABELS
    )
    
    # -------------------------------------------------------------------------
    # √âTAPE 5 : Sauvegarde du pipeline et des m√©tadonn√©es
    # -------------------------------------------------------------------------
    print("\n" + "-" * 70)
    print("√âTAPE 5 : Sauvegarde du mod√®le")
    print("-" * 70)
    
    ensure_models_dir()
    
    # Cr√©er le dictionnaire pipeline
    pipeline_dict = {
        'model': final_model,
        'tfidf': tfidf_final,
        'text_column': TEXT_COLUMN,
        'numeric_columns': NUMERIC_COLUMNS,
        'target_column': TARGET_COLUMN,
        'labels': URGENCY_LABELS
    }
    
    save_model(pipeline_dict, PIPELINE_FILE, "Pipeline Urgence")
    
    # Sauvegarder les m√©tadonn√©es
    metadata = {
        'urgency_model': {
            'training_date': datetime.now().isoformat(),
            'algorithm': 'LogisticRegression',
            'features': {
                'text': TEXT_COLUMN,
                'numeric': NUMERIC_COLUMNS,
                'tfidf_params': TFIDF_PARAMS
            },
            'classes': URGENCY_LABELS,
            'metrics': {
                'oof_train': oof_metrics,
                'validation': val_metrics,
                'test': test_metrics
            },
            'n_train_samples': len(df_train),
            'n_features': X_train_combined.shape[1]
        }
    }
    save_metadata(metadata)
    
    # -------------------------------------------------------------------------
    # R√âSUM√â FINAL
    # -------------------------------------------------------------------------
    print("\n" + "=" * 70)
    print("R√âSUM√â - MOD√àLE D'URGENCE")
    print("=" * 70)
    print(f"""
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  MOD√àLE D'URGENCE (Classification 3 classes)                        ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  Features : TF-IDF(text_full) + nb_mots                             ‚îÇ
    ‚îÇ  Algorithme : LogisticRegression (balanced)                         ‚îÇ
    ‚îÇ                                                                     ‚îÇ
    ‚îÇ  üìä PERFORMANCES :                                                  ‚îÇ
    ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
    ‚îÇ  Train (OOF)  : Accuracy={oof_metrics['accuracy']:.4f}  F1-Macro={oof_metrics['f1_macro']:.4f}  ‚îÇ
    ‚îÇ  Validation   : Accuracy={val_metrics['accuracy']:.4f}  F1-Macro={val_metrics['f1_macro']:.4f}  ‚îÇ
    ‚îÇ  Test         : Accuracy={test_metrics['accuracy']:.4f}  F1-Macro={test_metrics['f1_macro']:.4f}  ‚îÇ
    ‚îÇ                                                                     ‚îÇ
    ‚îÇ  ‚úÖ Pipeline sauvegard√© : models/{PIPELINE_FILE}              ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    """)
    
    return pipeline_dict, df_train, df_val, df_test


# =============================================================================
# FONCTION DE PR√âDICTION POUR UTILISATION EXTERNE
# =============================================================================
def predict_urgency(pipeline_dict: dict, X: pd.DataFrame) -> np.ndarray:
    """
    Fait des pr√©dictions d'urgence sur de nouvelles donn√©es.
    
    Args:
        pipeline_dict: Dictionnaire contenant le mod√®le et les transformers
        X: DataFrame avec les colonnes text_full et nb_mots
        
    Returns:
        Array de pr√©dictions
    """
    tfidf = pipeline_dict['tfidf']
    model = pipeline_dict['model']
    text_col = pipeline_dict['text_column']
    num_cols = pipeline_dict['numeric_columns']
    
    X_text = tfidf.transform(X[text_col].fillna(''))
    X_num = X[num_cols].values
    X_combined = hstack([X_text, csr_matrix(X_num)])
    
    return model.predict(X_combined)


# =============================================================================
# POINT D'ENTR√âE
# =============================================================================
if __name__ == "__main__":
    pipeline, df_train, df_val, df_test = train_urgency_model()
    
    # Sauvegarder les DataFrames avec les pr√©dictions pour les mod√®les suivants
    df_train.to_csv("data/train_with_urgence_pred.csv", index=False)
    df_val.to_csv("data/val_with_urgence_pred.csv", index=False)
    df_test.to_csv("data/test_with_urgence_pred.csv", index=False)
    
    print("\n‚úÖ DataFrames avec pr√©dictions d'urgence sauvegard√©s pour les mod√®les downstream")
    print("=" * 70)
