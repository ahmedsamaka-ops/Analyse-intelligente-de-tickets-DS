# Guide d'utilisation de la fonction ask_bot (RAG Complet)

## ğŸ¯ Vue d'ensemble

La fonction `ask_bot()` est une implÃ©mentation complÃ¨te de RAG (Retrieval Augmented Generation) qui :
1. **Recherche** les documents pertinents dans ChromaDB
2. **Construit** un prompt avec le contexte trouvÃ©
3. **Envoie** la requÃªte au LLM (Ollama/OpenAI/Mistral)
4. **Retourne** une rÃ©ponse basÃ©e uniquement sur les documents

## ğŸš€ DÃ©marrage rapide (Test en 1 commande)

```powershell
# Activez l'environnement virtuel
.venv\Scripts\Activate.ps1

# Lancez le test rapide
python src/rag/quick_start.py
```

Ce script va :
- âœ… VÃ©rifier les dÃ©pendances
- âœ… Initialiser ChromaDB avec 6 tickets de support
- âœ… Tester : "Comment rÃ©soudre un problÃ¨me de connexion Maroc Telecom?"

## ğŸ“‹ Ã‰tapes dÃ©taillÃ©es

### 1. Initialiser la base de connaissances

```powershell
python src/rag/init_chroma.py
```

Cela crÃ©e une base ChromaDB dans `data/chroma_db/` avec 6 tickets :
- Connexion Maroc Telecom
- RÃ©initialisation mot de passe
- VPN Orange
- Imprimante rÃ©seau
- Lenteur Inwi
- Email Outlook

### 2. Configurer le LLM

**Option A : Ollama (Gratuit, Local)**
```powershell
# Installez Ollama si ce n'est pas fait
# https://ollama.ai/download

ollama serve
ollama pull llama3.2
```

**Option B : OpenAI/Mistral**
```env
# Modifiez .env
LLM_PROVIDER=openai
OPENAI_API_KEY=votre-clÃ©-ici
```

### 3. Tester ask_bot

**Test automatique avec 5 questions :**
```powershell
python src/rag/test_ask_bot.py
```

**Mode interactif (pose tes questions) :**
```powershell
python src/rag/test_ask_bot.py demo
```

## ğŸ’» Utilisation dans votre code

```python
from src.rag.chatbot import ask_bot

# Poser une question
result = ask_bot("Comment rÃ©soudre un problÃ¨me de connexion Maroc Telecom?")

# Afficher la rÃ©ponse
print(result['answer'])

# Voir les sources utilisÃ©es
print(f"Sources: {result['sources']}")

# AccÃ©der aux documents bruts
for doc in result['documents']:
    print(doc)
```

### Structure du rÃ©sultat

```python
{
    "answer": "La rÃ©ponse gÃ©nÃ©rÃ©e par le LLM",
    "sources": ["doc1", "doc2"],  # IDs des documents
    "documents": ["texte doc 1", "texte doc 2"],  # Textes complets
    "distances": [0.15, 0.23]  # Scores de similaritÃ©
}
```

## ğŸ”§ Architecture de ask_bot

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ask_bot(query) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰tape A: Recherche ChromaDB        â”‚
â”‚ - Vectorisation de la query        â”‚
â”‚ - Recherche de similaritÃ©          â”‚
â”‚ - RÃ©cupÃ©ration top N documents     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰tape B: Construction du contexte  â”‚
â”‚ - AgrÃ©gation des documents         â”‚
â”‚ - Formatage avec le template RAG   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰tape C: Envoi au LLM              â”‚
â”‚ - Application du template          â”‚
â”‚ - Appel API (OpenAI/Mistral/Ollama)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰tape D: Retour du rÃ©sultat        â”‚
â”‚ - RÃ©ponse + sources + mÃ©tadonnÃ©es  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š ParamÃ¨tres de ask_bot

```python
ask_bot(
    query: str,        # La question de l'utilisateur
    n_results: int = 3 # Nombre de documents Ã  rÃ©cupÃ©rer (dÃ©faut: 3)
) -> dict
```

## â“ Questions de test suggÃ©rÃ©es

1. "Comment rÃ©soudre un problÃ¨me de connexion Maroc Telecom?"
2. "RÃ©initialiser mon mot de passe oubliÃ©"
3. "Mon VPN ne fonctionne pas, que faire?"
4. "L'imprimante ne marche plus"
5. "Internet Inwi est trÃ¨s lent"
6. "Comment configurer Outlook?"

## ğŸ” RÃ©sultats attendus

Avec la question **"Comment rÃ©soudre un problÃ¨me de connexion Maroc Telecom?"** :

**Sources trouvÃ©es :** `doc1` (Ticket connexion Maroc Telecom)

**RÃ©ponse attendue :**
```
Pour rÃ©soudre un problÃ¨me de connexion Maroc Telecom:
1. VÃ©rifiez que le modem est bien allumÃ© (voyant vert)
2. RedÃ©marrez le modem (dÃ©branchez 30 secondes puis rebranchez)
3. VÃ©rifiez les cÃ¢bles RJ45 et RJ11
4. Si le problÃ¨me persiste, appelez le 888 (service client Maroc Telecom)

Le temps de rÃ©solution moyen est de 2 heures.
```

## ğŸ› DÃ©pannage

**Erreur : "Collection does not exist"**
```powershell
# Initialisez la base d'abord
python src/rag/init_chroma.py
```

**Erreur : "Ollama connection failed"**
```powershell
# Lancez Ollama
ollama serve
```

**Pas de rÃ©ponse pertinente**
- VÃ©rifiez que les documents sont bien dans ChromaDB
- Augmentez `n_results` pour chercher plus de documents
- Ajoutez plus de tickets de support dans `init_chroma.py`

## ğŸ“ Fichiers crÃ©Ã©s

- `src/rag/chatbot.py` - Fonctions LLM + ask_bot
- `src/rag/init_chroma.py` - Initialisation ChromaDB
- `src/rag/test_ask_bot.py` - Tests automatiques
- `src/rag/quick_start.py` - Script de dÃ©marrage rapide
- `data/chroma_db/` - Base de donnÃ©es vectorielle

## ğŸ“ Prochaines Ã©tapes

1. âœ… Testez ask_bot avec vos propres questions
2. ğŸ“š Ajoutez vos propres tickets dans `init_chroma.py`
3. ğŸ”§ IntÃ©grez ask_bot dans votre application Streamlit
4. ğŸš€ DÃ©ployez avec vos vraies donnÃ©es de tickets
